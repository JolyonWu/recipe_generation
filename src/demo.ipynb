{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('./model')\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from args import get_parser\n",
    "import pickle\n",
    "from model_full import get_model_full\n",
    "from model_fomer import  get_model_fomer\n",
    "from torchvision import transforms\n",
    "from utils.output_utils import prepare_output\n",
    "from PIL import Image\n",
    "import time\n",
    "from data_loader import get_loader\n",
    "from  data_loader import *\n",
    "data_dir = '/DATACENTER/3/wjl/Recipe_generation_our/'\n",
    "model_dir='/DATACENTER/3/wjl/Recipe_generation_our/recipe_generation/full/checkpoints/'\n",
    "# code will run in gpu if available and if the flag is set to True, else it will run on cpu\n",
    "use_gpu = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')\n",
    "map_loc = None if torch.cuda.is_available() and use_gpu else 'cpu'\n",
    "\n",
    "\n",
    "ingrs_vocab = pickle.load(open(os.path.join(data_dir, 'recipe_vocab_ingrs.pkl'), 'rb'))\n",
    "action_vocab = pickle.load(open(os.path.join(data_dir, 'recipe_vocab_action.pkl'), 'rb'))\n",
    "insts_vocab = pickle.load(open(os.path.join(data_dir, 'recipe_vocab_toks.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "import sys; sys.argv=['']; del sys\n",
    "args = get_parser()\n",
    "args.maxseqlen = 50\n",
    "\n",
    "\n",
    "greedy = [True, False, False, False]\n",
    "beam = [-1, -1, -1, -1]\n",
    "temperature = 1.0\n",
    "numgens = len(greedy)\n",
    "datasets={}\n",
    "data_loaders={}\n",
    "for split in ['train', 'test']:\n",
    "\n",
    "    transforms_list = []\n",
    "    transforms_list.append(transforms.CenterCrop(args.crop_size))\n",
    "    transforms_list.append(transforms.ToTensor())\n",
    "    transform = transforms.Compose(transforms_list)\n",
    "\n",
    "    max_num_samples = max(args.max_eval, args.batch_size) if split == 'test' else -1\n",
    "    data_loaders[split], datasets[split] = get_loader(args.recipe_dir, args.aux_data_dir, args.lmdb_data_dir, split,\n",
    "                                                      args.maxseqlen,\n",
    "                                                      args.maxnuminstrs,\n",
    "                                                      args.maxnumlabels,\n",
    "                                                      args.maxnumactions,\n",
    "                                                      args.maxnumims,\n",
    "                                                      transform, args.batch_size,\n",
    "                                                      shuffle=False, num_workers=args.num_workers,\n",
    "                                                      drop_last=True,\n",
    "                                                      max_num_samples=max_num_samples,\n",
    "                                                      use_lmdb=args.use_lmdb,\n",
    "                                                      suff=args.suff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ingr_vocab_size = datasets[split].get_ingrs_vocab_size()\n",
    "action_vocab_size = datasets[split].get_action_vocab_size()\n",
    "instrs_vocab_size = datasets[split].get_instrs_vocab_size()\n",
    "output_dim = instrs_vocab_size\n",
    "print (instrs_vocab_size, ingr_vocab_size,action_vocab_size)\n",
    "model = get_model_full(args, ingr_vocab_size,action_vocab_size,instrs_vocab_size)\n",
    "# Load the trained model parameters\n",
    "model_path = os.path.join(model_dir, 'model_0_.ckpt')\n",
    "model.load_state_dict(torch.load(model_path, map_location=map_loc))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print ('loaded model')\n",
    "print (\"Elapsed time:\", time.time() -t)\n",
    "print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for img_inputs, captions, ingr_gt,action_gt in data_loaders['test']:\n",
    "\n",
    "    length_steps = img_inputs.size(1)\n",
    "    img_inputs = img_inputs.to(device)\n",
    "    captions = captions.to(device)\n",
    "    ingr_gt = ingr_gt.to(device)\n",
    "    action_gt = action_gt.to(device)\n",
    "    for steps in range(length_steps):\n",
    "        image_step = img_inputs[:, steps, :, :, :]\n",
    "        caption_step = captions[:, steps, :]\n",
    "        ingrs_step = ingr_gt[:, steps, :]\n",
    "        action_step = action_gt[:, steps, :]\n",
    "        true_caps = caption_step.clone()[:, 1:].contiguous()\n",
    "        new_img_PIL = transforms.ToPILImage()(image_step.cpu().squeeze(0)).convert('RGB')\n",
    "        new_img_PIL.show()  # 处理后的PIL图片\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.sample(image_step, true_ingrs=None)\n",
    "            ingr_ids = outputs['ingr_ids'].cpu().numpy()\n",
    "            action_ids = outputs['action_ids'].cpu().numpy()\n",
    "            recipe_ids = outputs['recipe_ids'].cpu().numpy()\n",
    "            outs, valid = prepare_output(recipe_ids[0], ingr_ids[0],action_ids[0], insts_vocab,ingrs_vocab, action_vocab)\n",
    "\n",
    "            BOLD = '\\033[1m'\n",
    "            END = '\\033[0m'\n",
    "\n",
    "            print(BOLD + '\\nInstructions:' + END)\n",
    "            print('-' + ' '.join(outs['recipe']))\n",
    "\n",
    "            print(BOLD + '\\nIngredients:' + END)\n",
    "            print(', '.join(outs['ingrs']))\n",
    "\n",
    "            print(BOLD + '\\nActions:' + END)\n",
    "            print(', '.join(outs['action']))\n",
    "\n",
    "\n",
    "    print('=' * 20)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
